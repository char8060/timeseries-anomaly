{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "sys.path.insert(1, '/home/jupyter/ds_toolkit')\n",
    "from ds_toolkit import tools\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style='whitegrid',palette='muted',font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('timeseries_data.csv',parse_dates=['usage_date'],index_col='usage_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameter of interest\n",
    "#poi = 'acct_ttl_unit_hours'\n",
    "poi = 'z5'\n",
    "#poi = 'z10'\n",
    "#poi = 'z15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset.index,dataset[poi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset)*0.75)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train, test = dataset.iloc[0:train_size],dataset.iloc[train_size:len(dataset)]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train[[poi]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply transformation\n",
    "train[poi] = scaler.transform(train[[poi]])\n",
    "test[poi] = scaler.transform(test[[poi]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X,y,time_steps=1):\n",
    "    Xs, ys = [],[]\n",
    "    for i in range(len(X)-time_steps):\n",
    "        v=X.iloc[i:(i+time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 30\n",
    "\n",
    "X_train, y_train = create_dataset(train[[poi]],train[poi],TIME_STEPS)\n",
    "X_test, y_test = create_dataset(test[[poi]],test[poi],TIME_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea use LSTM to fit time series, when error(pred-actual) exceeds a threshold, label as anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "#first layer\n",
    "model.add(keras.layers.LSTM(\n",
    "    units=64,\n",
    "    input_shape=(X_train.shape[1],X_train.shape[2])\n",
    "))\n",
    "\n",
    "#add regularization layer\n",
    "model.add(keras.layers.Dropout(rate=0.1))\n",
    "\n",
    "model.add(keras.layers.RepeatVector(n=X_train.shape[1]))\n",
    "\n",
    "model.add(keras.layers.LSTM(\n",
    "    units=64,\n",
    "    return_sequences=True\n",
    "))\n",
    "\n",
    "#add another regularization layer\n",
    "model.add(keras.layers.Dropout(rate=0.1))\n",
    "\n",
    "#add time-distributed layer for anomaly detection\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(\n",
    "   units=X_train.shape[2]\n",
    ")))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=16,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False\n",
    "    )\n",
    "plt.plot(history.history['loss'],label='train')\n",
    "plt.plot(history.history['val_loss'],label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pred = model.predict(X_train)\n",
    "train_mae_loss = np.mean(np.abs(X_train_pred-X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_mae_loss,bins=60,kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do the same for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = model.predict(X_test)\n",
    "test_mae_loss = np.mean(np.abs(X_test_pred-X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.25\n",
    "BENCHMARK = 2.\n",
    "\n",
    "test_score_df = pd.DataFrame(index=test[TIME_STEPS:].index)\n",
    "test_score_df['loss'] = test_mae_loss\n",
    "test_score_df['threshold'] = THRESHOLD\n",
    "test_score_df['benchmark'] = BENCHMARK\n",
    "test_score_df['anomaly'] = test_score_df.loss > test_score_df.threshold\n",
    "test_score_df[poi] = test[TIME_STEPS:][poi]\n",
    "test_score_df['anomaly_benchmark'] = abs(scaler.inverse_transform(test_score_df[poi])) > test_score_df.benchmark\n",
    "#\n",
    "test_score_df['acct_ttl_unit_hours']=test[TIME_STEPS:]['acct_ttl_unit_hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae_loss.shape\n",
    "X_test_pred.shape\n",
    "#test_score_df['pred'] = X_test_pred[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_score_df.index,test_score_df.loss,label='loss')\n",
    "sns.scatterplot(test_score_df.index,test_score_df.loss,\n",
    "    color=sns.color_palette()[4],\n",
    "    s=52,\n",
    "    label='data'\n",
    ")\n",
    "plt.plot(test_score_df.index,test_score_df.threshold,label='threshold')\n",
    "plt.xticks(rotation=25)\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "test_score_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create anomalies dataset\n",
    "anomalies = test_score_df[test_score_df.anomaly == True]\n",
    "benchmarks = test_score_df[test_score_df.anomaly_benchmark == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    test[TIME_STEPS:].index,\n",
    "    scaler.inverse_transform(test[TIME_STEPS:][poi]),\n",
    "    label=poi\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    test[TIME_STEPS:].index,\n",
    "    scaler.inverse_transform(test[TIME_STEPS:][poi]),\n",
    "    color=sns.color_palette()[4],\n",
    "    s=52,\n",
    "    label='data'\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    anomalies.index,\n",
    "    scaler.inverse_transform(anomalies[poi]),\n",
    "    color=sns.color_palette()[3],\n",
    "    s=52,\n",
    "    label='anomaly'\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=25)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    test[TIME_STEPS:].index,\n",
    "    scaler.inverse_transform(test[TIME_STEPS:]['acct_ttl_unit_hours']),\n",
    "    label='acct_ttl_unit_hours'\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    test[TIME_STEPS:].index,\n",
    "    scaler.inverse_transform(test[TIME_STEPS:]['acct_ttl_unit_hours']),\n",
    "    color=sns.color_palette()[1],\n",
    "    s=92,\n",
    "   label='actual'\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    anomalies.index,\n",
    "    scaler.inverse_transform(anomalies['acct_ttl_unit_hours']),\n",
    "    color=sns.color_palette()[2],\n",
    "    s=92,\n",
    "   label='anomaly'\n",
    ")\n",
    "\n",
    "#sns.scatterplot(\n",
    "#    benchmarks.index,\n",
    "#    scaler.inverse_transform(benchmarks['acct_ttl_unit_hours']),\n",
    "#    color=sns.color_palette()[3],\n",
    "#    s=92,\n",
    "#    label='benchmark'\n",
    "#)\n",
    "\n",
    "plt.xticks(rotation=25)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
